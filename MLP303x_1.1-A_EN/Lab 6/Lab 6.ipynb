{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab 6.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1T_7xRjnTVow5SJzDmf0I8gU1dl2QTQeK","authorship_tag":"ABX9TyMXZmxngpa1W5UHQ9V7vu+7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"M65N8QcysjzP"},"source":["## Implementing binary decision trees\n","* Use Pandas to do some feature engineering.\n","* Transform categorical variables into binary variables.\n","* Write a function to compute the number of misclassified examples in an intermediate node.\n","* Write a function to find the best feature to split on.\n","* Build a binary decision tree from scratch.\n","* Make predictions using the decision tree.\n","* Evaluate the accuracy of the decision tree.\n","* Visualize the decision at the root node.\n","\n","**Important Note**: In this assignment, we will focus on building decision trees where the data contain **only binary (0 or 1) features**. This allows us to avoid dealing with:\n","* Multiple intermediate nodes in a split\n","* The thresholding issues of real-valued features.\n","\n","This assignment **may be challenging**, so brace yourself :)"]},{"cell_type":"code","metadata":{"id":"SUz0VYBksjze"},"source":["# Import some libs\n","\n","import pandas\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GE2PVHTwsjzg"},"source":["# Load the lending club dataset\n","We will be using the same [LendingClub](https://www.lendingclub.com/) dataset as in the previous assignment."]},{"cell_type":"code","metadata":{"id":"TVw7oHvJsjzg"},"source":["loans_df = pandas.read_csv('/content/drive/MyDrive/FUNIX Progress/MLP303x_1.1-A_EN/data/lending-club-data.csv', low_memory=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TqF9cyIfQjqq","executionInfo":{"status":"ok","timestamp":1620280826692,"user_tz":-420,"elapsed":892,"user":{"displayName":"Khanh Vuong Tuan","photoUrl":"","userId":"10783698511148593600"}},"outputId":"df9035e6-e6fc-4395-b15a-cb617b3b81ef"},"source":["loans_df.columns"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['id', 'member_id', 'loan_amnt', 'funded_amnt', 'funded_amnt_inv',\n","       'term', 'int_rate', 'installment', 'grade', 'sub_grade', 'emp_title',\n","       'emp_length', 'home_ownership', 'annual_inc', 'is_inc_v', 'issue_d',\n","       'loan_status', 'pymnt_plan', 'url', 'desc', 'purpose', 'title',\n","       'zip_code', 'addr_state', 'dti', 'delinq_2yrs', 'earliest_cr_line',\n","       'inq_last_6mths', 'mths_since_last_delinq', 'mths_since_last_record',\n","       'open_acc', 'pub_rec', 'revol_bal', 'revol_util', 'total_acc',\n","       'initial_list_status', 'out_prncp', 'out_prncp_inv', 'total_pymnt',\n","       'total_pymnt_inv', 'total_rec_prncp', 'total_rec_int',\n","       'total_rec_late_fee', 'recoveries', 'collection_recovery_fee',\n","       'last_pymnt_d', 'last_pymnt_amnt', 'next_pymnt_d', 'last_credit_pull_d',\n","       'collections_12_mths_ex_med', 'mths_since_last_major_derog',\n","       'policy_code', 'not_compliant', 'status', 'inactive_loans', 'bad_loans',\n","       'emp_length_num', 'grade_num', 'sub_grade_num', 'delinq_2yrs_zero',\n","       'pub_rec_zero', 'collections_12_mths_zero', 'short_emp',\n","       'payment_inc_ratio', 'final_d', 'last_delinq_none', 'last_record_none',\n","       'last_major_derog_none'],\n","      dtype='object')"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HtOGj7IIRCRI","executionInfo":{"status":"ok","timestamp":1620281129376,"user_tz":-420,"elapsed":1036,"user":{"displayName":"Khanh Vuong Tuan","photoUrl":"","userId":"10783698511148593600"}},"outputId":"6b298203-cc21-44be-97e5-6d5a9ed2cdd9"},"source":["loans_df.groupby('bad_loans').count()['id']"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["bad_loans\n","0    99457\n","1    23150\n","Name: id, dtype: int64"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"markdown","metadata":{"id":"iKRvQZQvsjzh"},"source":["Like the previous assignment, we reassign the labels to have +1 for a safe loan, and -1 for a risky (bad) loan."]},{"cell_type":"code","metadata":{"id":"oBWzqZeosjzi","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1620281164252,"user_tz":-420,"elapsed":924,"user":{"displayName":"Khanh Vuong Tuan","photoUrl":"","userId":"10783698511148593600"}},"outputId":"491d8cc0-3e55-4f3b-9cf5-efdaf01facc7"},"source":["# safe_loans =  1 => safe\n","# safe_loans = -1 => risky\n","loans_df['safe_loans'] = loans_df['bad_loans'].apply(lambda x : +1 if x==0 else -1)\n","loans_df.drop(columns=['bad_loans'])"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>member_id</th>\n","      <th>loan_amnt</th>\n","      <th>funded_amnt</th>\n","      <th>funded_amnt_inv</th>\n","      <th>term</th>\n","      <th>int_rate</th>\n","      <th>installment</th>\n","      <th>grade</th>\n","      <th>sub_grade</th>\n","      <th>emp_title</th>\n","      <th>emp_length</th>\n","      <th>home_ownership</th>\n","      <th>annual_inc</th>\n","      <th>is_inc_v</th>\n","      <th>issue_d</th>\n","      <th>loan_status</th>\n","      <th>pymnt_plan</th>\n","      <th>url</th>\n","      <th>desc</th>\n","      <th>purpose</th>\n","      <th>title</th>\n","      <th>zip_code</th>\n","      <th>addr_state</th>\n","      <th>dti</th>\n","      <th>delinq_2yrs</th>\n","      <th>earliest_cr_line</th>\n","      <th>inq_last_6mths</th>\n","      <th>mths_since_last_delinq</th>\n","      <th>mths_since_last_record</th>\n","      <th>open_acc</th>\n","      <th>pub_rec</th>\n","      <th>revol_bal</th>\n","      <th>revol_util</th>\n","      <th>total_acc</th>\n","      <th>initial_list_status</th>\n","      <th>out_prncp</th>\n","      <th>out_prncp_inv</th>\n","      <th>total_pymnt</th>\n","      <th>total_pymnt_inv</th>\n","      <th>total_rec_prncp</th>\n","      <th>total_rec_int</th>\n","      <th>total_rec_late_fee</th>\n","      <th>recoveries</th>\n","      <th>collection_recovery_fee</th>\n","      <th>last_pymnt_d</th>\n","      <th>last_pymnt_amnt</th>\n","      <th>next_pymnt_d</th>\n","      <th>last_credit_pull_d</th>\n","      <th>collections_12_mths_ex_med</th>\n","      <th>mths_since_last_major_derog</th>\n","      <th>policy_code</th>\n","      <th>not_compliant</th>\n","      <th>status</th>\n","      <th>inactive_loans</th>\n","      <th>emp_length_num</th>\n","      <th>grade_num</th>\n","      <th>sub_grade_num</th>\n","      <th>delinq_2yrs_zero</th>\n","      <th>pub_rec_zero</th>\n","      <th>collections_12_mths_zero</th>\n","      <th>short_emp</th>\n","      <th>payment_inc_ratio</th>\n","      <th>final_d</th>\n","      <th>last_delinq_none</th>\n","      <th>last_record_none</th>\n","      <th>last_major_derog_none</th>\n","      <th>safe_loans</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1077501</td>\n","      <td>1296599</td>\n","      <td>5000</td>\n","      <td>5000</td>\n","      <td>4975</td>\n","      <td>36 months</td>\n","      <td>10.65</td>\n","      <td>162.87</td>\n","      <td>B</td>\n","      <td>B2</td>\n","      <td>NaN</td>\n","      <td>10+ years</td>\n","      <td>RENT</td>\n","      <td>24000.0</td>\n","      <td>Verified</td>\n","      <td>20111201T000000</td>\n","      <td>Fully Paid</td>\n","      <td>n</td>\n","      <td>https://www.lendingclub.com/browse/loanDetail....</td>\n","      <td>Borrower added on 12/22/11 &gt; I need to upgra...</td>\n","      <td>credit_card</td>\n","      <td>Computer</td>\n","      <td>860xx</td>\n","      <td>AZ</td>\n","      <td>27.65</td>\n","      <td>0.0</td>\n","      <td>19850101T000000</td>\n","      <td>1.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>13648</td>\n","      <td>83.7</td>\n","      <td>9.0</td>\n","      <td>f</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5861.07</td>\n","      <td>5831.78</td>\n","      <td>5000.00</td>\n","      <td>861.07</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.000</td>\n","      <td>20150101T000000</td>\n","      <td>171.62</td>\n","      <td>NaN</td>\n","      <td>20150101T000000</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Fully Paid</td>\n","      <td>1</td>\n","      <td>11</td>\n","      <td>5</td>\n","      <td>0.4</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0</td>\n","      <td>8.143500</td>\n","      <td>20141201T000000</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1077430</td>\n","      <td>1314167</td>\n","      <td>2500</td>\n","      <td>2500</td>\n","      <td>2500</td>\n","      <td>60 months</td>\n","      <td>15.27</td>\n","      <td>59.83</td>\n","      <td>C</td>\n","      <td>C4</td>\n","      <td>Ryder</td>\n","      <td>&lt; 1 year</td>\n","      <td>RENT</td>\n","      <td>30000.0</td>\n","      <td>Source Verified</td>\n","      <td>20111201T000000</td>\n","      <td>Charged Off</td>\n","      <td>n</td>\n","      <td>https://www.lendingclub.com/browse/loanDetail....</td>\n","      <td>Borrower added on 12/22/11 &gt; I plan to use t...</td>\n","      <td>car</td>\n","      <td>bike</td>\n","      <td>309xx</td>\n","      <td>GA</td>\n","      <td>1.00</td>\n","      <td>0.0</td>\n","      <td>19990401T000000</td>\n","      <td>5.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>1687</td>\n","      <td>9.4</td>\n","      <td>4.0</td>\n","      <td>f</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1008.71</td>\n","      <td>1008.71</td>\n","      <td>456.46</td>\n","      <td>435.17</td>\n","      <td>0.00</td>\n","      <td>117.08</td>\n","      <td>1.110</td>\n","      <td>20130401T000000</td>\n","      <td>119.66</td>\n","      <td>NaN</td>\n","      <td>20130901T000000</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Charged Off</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>0.8</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>2.393200</td>\n","      <td>20161201T000000</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1077175</td>\n","      <td>1313524</td>\n","      <td>2400</td>\n","      <td>2400</td>\n","      <td>2400</td>\n","      <td>36 months</td>\n","      <td>15.96</td>\n","      <td>84.33</td>\n","      <td>C</td>\n","      <td>C5</td>\n","      <td>NaN</td>\n","      <td>10+ years</td>\n","      <td>RENT</td>\n","      <td>12252.0</td>\n","      <td>Not Verified</td>\n","      <td>20111201T000000</td>\n","      <td>Fully Paid</td>\n","      <td>n</td>\n","      <td>https://www.lendingclub.com/browse/loanDetail....</td>\n","      <td>NaN</td>\n","      <td>small_business</td>\n","      <td>real estate business</td>\n","      <td>606xx</td>\n","      <td>IL</td>\n","      <td>8.72</td>\n","      <td>0.0</td>\n","      <td>20011101T000000</td>\n","      <td>2.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>2.0</td>\n","      <td>0.0</td>\n","      <td>2956</td>\n","      <td>98.5</td>\n","      <td>10.0</td>\n","      <td>f</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>3003.65</td>\n","      <td>3003.65</td>\n","      <td>2400.00</td>\n","      <td>603.65</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.000</td>\n","      <td>20140601T000000</td>\n","      <td>649.91</td>\n","      <td>NaN</td>\n","      <td>20150201T000000</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Fully Paid</td>\n","      <td>1</td>\n","      <td>11</td>\n","      <td>4</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0</td>\n","      <td>8.259550</td>\n","      <td>20141201T000000</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1076863</td>\n","      <td>1277178</td>\n","      <td>10000</td>\n","      <td>10000</td>\n","      <td>10000</td>\n","      <td>36 months</td>\n","      <td>13.49</td>\n","      <td>339.31</td>\n","      <td>C</td>\n","      <td>C1</td>\n","      <td>AIR RESOURCES BOARD</td>\n","      <td>10+ years</td>\n","      <td>RENT</td>\n","      <td>49200.0</td>\n","      <td>Source Verified</td>\n","      <td>20111201T000000</td>\n","      <td>Fully Paid</td>\n","      <td>n</td>\n","      <td>https://www.lendingclub.com/browse/loanDetail....</td>\n","      <td>Borrower added on 12/21/11 &gt; to pay for prop...</td>\n","      <td>other</td>\n","      <td>personel</td>\n","      <td>917xx</td>\n","      <td>CA</td>\n","      <td>20.00</td>\n","      <td>0.0</td>\n","      <td>19960201T000000</td>\n","      <td>1.0</td>\n","      <td>35.0</td>\n","      <td>NaN</td>\n","      <td>10.0</td>\n","      <td>0.0</td>\n","      <td>5598</td>\n","      <td>21.0</td>\n","      <td>37.0</td>\n","      <td>f</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>12226.30</td>\n","      <td>12226.30</td>\n","      <td>10000.00</td>\n","      <td>2209.33</td>\n","      <td>16.97</td>\n","      <td>0.00</td>\n","      <td>0.000</td>\n","      <td>20150101T000000</td>\n","      <td>357.48</td>\n","      <td>NaN</td>\n","      <td>20150101T000000</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Fully Paid</td>\n","      <td>1</td>\n","      <td>11</td>\n","      <td>4</td>\n","      <td>0.2</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0</td>\n","      <td>8.275850</td>\n","      <td>20141201T000000</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1075269</td>\n","      <td>1311441</td>\n","      <td>5000</td>\n","      <td>5000</td>\n","      <td>5000</td>\n","      <td>36 months</td>\n","      <td>7.90</td>\n","      <td>156.46</td>\n","      <td>A</td>\n","      <td>A4</td>\n","      <td>Veolia Transportaton</td>\n","      <td>3 years</td>\n","      <td>RENT</td>\n","      <td>36000.0</td>\n","      <td>Source Verified</td>\n","      <td>20111201T000000</td>\n","      <td>Fully Paid</td>\n","      <td>n</td>\n","      <td>https://www.lendingclub.com/browse/loanDetail....</td>\n","      <td>NaN</td>\n","      <td>wedding</td>\n","      <td>My wedding loan I promise to pay back</td>\n","      <td>852xx</td>\n","      <td>AZ</td>\n","      <td>11.20</td>\n","      <td>0.0</td>\n","      <td>20041101T000000</td>\n","      <td>3.0</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>9.0</td>\n","      <td>0.0</td>\n","      <td>7963</td>\n","      <td>28.3</td>\n","      <td>12.0</td>\n","      <td>f</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>5631.38</td>\n","      <td>5631.38</td>\n","      <td>5000.00</td>\n","      <td>631.38</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.000</td>\n","      <td>20150101T000000</td>\n","      <td>161.03</td>\n","      <td>NaN</td>\n","      <td>20150201T000000</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Fully Paid</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>0.8</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0</td>\n","      <td>5.215330</td>\n","      <td>20141201T000000</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>122602</th>\n","      <td>9856168</td>\n","      <td>11708132</td>\n","      <td>6000</td>\n","      <td>6000</td>\n","      <td>6000</td>\n","      <td>60 months</td>\n","      <td>23.40</td>\n","      <td>170.53</td>\n","      <td>E</td>\n","      <td>E5</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>MORTGAGE</td>\n","      <td>45600.0</td>\n","      <td>Source Verified</td>\n","      <td>20140101T000000</td>\n","      <td>Charged Off</td>\n","      <td>n</td>\n","      <td>https://www.lendingclub.com/browse/loanDetail....</td>\n","      <td>Borrower added on 12/13/13 &gt; Having major me...</td>\n","      <td>medical</td>\n","      <td>Medical</td>\n","      <td>317xx</td>\n","      <td>GA</td>\n","      <td>1.50</td>\n","      <td>1.0</td>\n","      <td>19840101T000000</td>\n","      <td>0.0</td>\n","      <td>15.0</td>\n","      <td>NaN</td>\n","      <td>3.0</td>\n","      <td>0.0</td>\n","      <td>1199</td>\n","      <td>14.6</td>\n","      <td>13.0</td>\n","      <td>f</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>511.49</td>\n","      <td>511.49</td>\n","      <td>163.71</td>\n","      <td>347.78</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.000</td>\n","      <td>20140401T000000</td>\n","      <td>170.53</td>\n","      <td>NaN</td>\n","      <td>20140901T000000</td>\n","      <td>0.0</td>\n","      <td>15.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Charged Off</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>1</td>\n","      <td>4.487630</td>\n","      <td>20190101T000000</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>122603</th>\n","      <td>9795013</td>\n","      <td>11647121</td>\n","      <td>15250</td>\n","      <td>15250</td>\n","      <td>15250</td>\n","      <td>36 months</td>\n","      <td>17.57</td>\n","      <td>548.05</td>\n","      <td>D</td>\n","      <td>D2</td>\n","      <td>Installer</td>\n","      <td>10+ years</td>\n","      <td>MORTGAGE</td>\n","      <td>65000.0</td>\n","      <td>Verified</td>\n","      <td>20140101T000000</td>\n","      <td>Fully Paid</td>\n","      <td>n</td>\n","      <td>https://www.lendingclub.com/browse/loanDetail....</td>\n","      <td>Borrower added on 12/11/13 &gt; Pay off high in...</td>\n","      <td>debt_consolidation</td>\n","      <td>Fresh</td>\n","      <td>190xx</td>\n","      <td>PA</td>\n","      <td>11.26</td>\n","      <td>1.0</td>\n","      <td>19980701T000000</td>\n","      <td>2.0</td>\n","      <td>23.0</td>\n","      <td>54.0</td>\n","      <td>8.0</td>\n","      <td>2.0</td>\n","      <td>6122</td>\n","      <td>15.2</td>\n","      <td>26.0</td>\n","      <td>f</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>15904.90</td>\n","      <td>15905.00</td>\n","      <td>15250.00</td>\n","      <td>654.95</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.000</td>\n","      <td>20140401T000000</td>\n","      <td>14810.30</td>\n","      <td>NaN</td>\n","      <td>20140401T000000</td>\n","      <td>0.0</td>\n","      <td>56.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Fully Paid</td>\n","      <td>1</td>\n","      <td>11</td>\n","      <td>3</td>\n","      <td>0.4</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0</td>\n","      <td>10.117800</td>\n","      <td>20170101T000000</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>122604</th>\n","      <td>9695736</td>\n","      <td>11547808</td>\n","      <td>8525</td>\n","      <td>8525</td>\n","      <td>8525</td>\n","      <td>60 months</td>\n","      <td>18.25</td>\n","      <td>217.65</td>\n","      <td>D</td>\n","      <td>D3</td>\n","      <td>MANAGER</td>\n","      <td>5 years</td>\n","      <td>MORTGAGE</td>\n","      <td>37536.0</td>\n","      <td>Verified</td>\n","      <td>20140101T000000</td>\n","      <td>Charged Off</td>\n","      <td>n</td>\n","      <td>https://www.lendingclub.com/browse/loanDetail....</td>\n","      <td>NaN</td>\n","      <td>medical</td>\n","      <td>Medical expenses</td>\n","      <td>011xx</td>\n","      <td>MA</td>\n","      <td>12.28</td>\n","      <td>4.0</td>\n","      <td>19941101T000000</td>\n","      <td>0.0</td>\n","      <td>3.0</td>\n","      <td>NaN</td>\n","      <td>12.0</td>\n","      <td>0.0</td>\n","      <td>5318</td>\n","      <td>10.7</td>\n","      <td>26.0</td>\n","      <td>f</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2029.93</td>\n","      <td>2029.93</td>\n","      <td>360.08</td>\n","      <td>510.45</td>\n","      <td>0.00</td>\n","      <td>1159.40</td>\n","      <td>11.594</td>\n","      <td>20140501T000000</td>\n","      <td>217.65</td>\n","      <td>NaN</td>\n","      <td>20141001T000000</td>\n","      <td>0.0</td>\n","      <td>4.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Charged Off</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>3</td>\n","      <td>0.6</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0</td>\n","      <td>6.958120</td>\n","      <td>20190101T000000</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>122605</th>\n","      <td>9684700</td>\n","      <td>11536848</td>\n","      <td>22000</td>\n","      <td>22000</td>\n","      <td>22000</td>\n","      <td>60 months</td>\n","      <td>19.97</td>\n","      <td>582.50</td>\n","      <td>D</td>\n","      <td>D5</td>\n","      <td>Chief of Interpretation (Park Ranger)</td>\n","      <td>10+ years</td>\n","      <td>MORTGAGE</td>\n","      <td>78000.0</td>\n","      <td>Verified</td>\n","      <td>20140101T000000</td>\n","      <td>Charged Off</td>\n","      <td>n</td>\n","      <td>https://www.lendingclub.com/browse/loanDetail....</td>\n","      <td>NaN</td>\n","      <td>debt_consolidation</td>\n","      <td>Debt consolidation</td>\n","      <td>377xx</td>\n","      <td>TN</td>\n","      <td>18.45</td>\n","      <td>0.0</td>\n","      <td>19970601T000000</td>\n","      <td>5.0</td>\n","      <td>NaN</td>\n","      <td>116.0</td>\n","      <td>18.0</td>\n","      <td>1.0</td>\n","      <td>18238</td>\n","      <td>46.3</td>\n","      <td>30.0</td>\n","      <td>f</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>4677.92</td>\n","      <td>4677.92</td>\n","      <td>1837.04</td>\n","      <td>2840.88</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.000</td>\n","      <td>20141201T000000</td>\n","      <td>17.50</td>\n","      <td>NaN</td>\n","      <td>20150201T000000</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Charged Off</td>\n","      <td>1</td>\n","      <td>11</td>\n","      <td>3</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0</td>\n","      <td>8.961540</td>\n","      <td>20190101T000000</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>122606</th>\n","      <td>9604874</td>\n","      <td>11457002</td>\n","      <td>2000</td>\n","      <td>2000</td>\n","      <td>2000</td>\n","      <td>36 months</td>\n","      <td>7.90</td>\n","      <td>62.59</td>\n","      <td>A</td>\n","      <td>A4</td>\n","      <td>Server Engineer Lead</td>\n","      <td>3 years</td>\n","      <td>OWN</td>\n","      <td>83000.0</td>\n","      <td>Verified</td>\n","      <td>20140101T000000</td>\n","      <td>Fully Paid</td>\n","      <td>n</td>\n","      <td>https://www.lendingclub.com/browse/loanDetail....</td>\n","      <td>NaN</td>\n","      <td>credit_card</td>\n","      <td>Credit card refinancing</td>\n","      <td>913xx</td>\n","      <td>CA</td>\n","      <td>5.39</td>\n","      <td>3.0</td>\n","      <td>20030201T000000</td>\n","      <td>1.0</td>\n","      <td>13.0</td>\n","      <td>NaN</td>\n","      <td>21.0</td>\n","      <td>0.0</td>\n","      <td>11404</td>\n","      <td>21.5</td>\n","      <td>27.0</td>\n","      <td>w</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>2126.58</td>\n","      <td>2126.58</td>\n","      <td>2000.00</td>\n","      <td>126.58</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","      <td>0.000</td>\n","      <td>20141201T000000</td>\n","      <td>1500.68</td>\n","      <td>NaN</td>\n","      <td>20150201T000000</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>Fully Paid</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>0.8</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>1.0</td>\n","      <td>0</td>\n","      <td>0.904916</td>\n","      <td>20170101T000000</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>122607 rows × 68 columns</p>\n","</div>"],"text/plain":["             id  member_id  ...  last_major_derog_none  safe_loans\n","0       1077501    1296599  ...                      1           1\n","1       1077430    1314167  ...                      1          -1\n","2       1077175    1313524  ...                      1           1\n","3       1076863    1277178  ...                      1           1\n","4       1075269    1311441  ...                      1           1\n","...         ...        ...  ...                    ...         ...\n","122602  9856168   11708132  ...                      0          -1\n","122603  9795013   11647121  ...                      0           1\n","122604  9695736   11547808  ...                      0          -1\n","122605  9684700   11536848  ...                      1          -1\n","122606  9604874   11457002  ...                      1           1\n","\n","[122607 rows x 68 columns]"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"SeoIAbRTsjzi"},"source":["Unlike the previous assignment where we used several features, in this assignment, we will just be using 4 categorical\n","features: \n","\n","1. grade of the loan \n","2. the length of the loan term\n","3. the home ownership status: own, mortgage, rent\n","4. number of years of employment.\n","\n","Since we are building a binary decision tree, we will have to convert these categorical features to a binary representation in a subsequent section using 1-hot encoding."]},{"cell_type":"code","metadata":{"id":"YowJKyFpsjzj"},"source":["features = ['grade',              # grade of the loan\n","            'term',               # the term of the loan\n","            'home_ownership',     # home_ownership status: own, mortgage or rent\n","            'emp_length',         # number of years of employment\n","           ]\n","target = 'safe_loans'\n","loans_df = loans_df[features + [target]]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vmuklB4ksjzk"},"source":["Let's explore what the dataset looks like."]},{"cell_type":"code","metadata":{"id":"K-lkFc0fsjzk","colab":{"base_uri":"https://localhost:8080/","height":195},"executionInfo":{"status":"ok","timestamp":1620280598379,"user_tz":-420,"elapsed":9305,"user":{"displayName":"Khanh Vuong Tuan","photoUrl":"","userId":"10783698511148593600"}},"outputId":"2cd9f394-83dc-4957-9871-a3f10d25486f"},"source":["loans_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>grade</th>\n","      <th>term</th>\n","      <th>home_ownership</th>\n","      <th>emp_length</th>\n","      <th>safe_loans</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>B</td>\n","      <td>36 months</td>\n","      <td>RENT</td>\n","      <td>10+ years</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>C</td>\n","      <td>60 months</td>\n","      <td>RENT</td>\n","      <td>&lt; 1 year</td>\n","      <td>-1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>C</td>\n","      <td>36 months</td>\n","      <td>RENT</td>\n","      <td>10+ years</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>C</td>\n","      <td>36 months</td>\n","      <td>RENT</td>\n","      <td>10+ years</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>A</td>\n","      <td>36 months</td>\n","      <td>RENT</td>\n","      <td>3 years</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  grade        term home_ownership emp_length  safe_loans\n","0     B   36 months           RENT  10+ years           1\n","1     C   60 months           RENT   < 1 year          -1\n","2     C   36 months           RENT  10+ years           1\n","3     C   36 months           RENT  10+ years           1\n","4     A   36 months           RENT    3 years           1"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"JBUYLmCPsjzl"},"source":["## Subsample dataset to make sure classes are balanced\n","Just as we did in the previous assignment, we will undersample the larger class (safe loans) in order to balance out our dataset. This means we are throwing away many data points. We use `seed=1` so everyone gets the same results."]},{"cell_type":"code","metadata":{"id":"4X4LCNrUsjzm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620281300462,"user_tz":-420,"elapsed":1083,"user":{"displayName":"Khanh Vuong Tuan","photoUrl":"","userId":"10783698511148593600"}},"outputId":"4cab9506-e3b9-448c-ba15-9c7d458c7de5"},"source":["safe_loans_raw = loans_df[loans_df[target] == +1]\n","risky_loans_raw = loans_df[loans_df[target] == -1]\n","\n","# Since there are fewer risky loans than safe loans, find the ratio of the sizes\n","# and use that percentage to undersample the safe loans.\n","percentage = risky_loans_raw.shape[0]/safe_loans_raw.shape[0]\n","\n","risky_loans = risky_loans_raw\n","safe_loans = safe_loans_raw.sample(frac=percentage, random_state=1)\n","\n","# Append the risky_loans with the downsampled version of safe_loans\n","loans_data = risky_loans.append(safe_loans)\n","\n","print(\"Percentage of safe loans                 : {}\".format(safe_loans.shape[0] / loans_data.shape[0]))\n","print(\"Percentage of risky loans                : {}\".format(risky_loans.shape[0] / loans_data.shape[0]))\n","print(\"Total number of loans in our new dataset : {}\".format(loans_data.shape[0]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Percentage of safe loans                 : 0.5\n","Percentage of risky loans                : 0.5\n","Total number of loans in our new dataset : 46300\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"6cwArsYqsjzn"},"source":["**Note:** There are many approaches for dealing with imbalanced data, including some where we modify the learning algorithm. These approaches are beyond the scope of this course, but some of them are reviewed in \"[Learning from Imbalanced Data](http://www.ele.uri.edu/faculty/he/PDFfiles/ImbalancedLearning.pdf)\" by Haibo He and Edwardo A. Garcia, *IEEE Transactions on Knowledge and Data Engineering* **21**(9) (June 26, 2009), p. 1263–1284. For this assignment, we use the simplest possible approach, where we subsample the overly represented class to get a more balanced dataset. In general, and especially when the data is highly imbalanced, we recommend using more advanced methods."]},{"cell_type":"markdown","metadata":{"id":"qI8UpjzNsjzn"},"source":["## Transform categorical data into binary features\n","In this assignment, we will implement **binary decision trees** (decision trees for binary features, a specific case of categorical variables taking on two values, e.g., true/false). Since all of our features are currently categorical features, we want to turn them into binary features. \n","\n","For instance, the **home_ownership** feature represents the home ownership status of the loanee, which is either `own`, `mortgage` or `rent`. For example, if a data point has the feature \n","```\n","   {'home_ownership': 'RENT'}\n","```\n","we want to turn this into three features: \n","```\n"," { \n","   'home_ownership = OWN'      : 0, \n","   'home_ownership = MORTGAGE' : 0, \n","   'home_ownership = RENT'     : 1\n"," }\n","```"]},{"cell_type":"code","metadata":{"id":"GIcrvGIcsjzo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620281519190,"user_tz":-420,"elapsed":871,"user":{"displayName":"Khanh Vuong Tuan","photoUrl":"","userId":"10783698511148593600"}},"outputId":"dc6de7f6-2a3f-467a-c2ba-b77e264a4b00"},"source":["print(loans_data.dtypes)\n","categorical_variables = list(loans_data.select_dtypes(include=['object']).columns)\n","print(categorical_variables)\n","\n","one_hot_data = pandas.get_dummies(loans_data[categorical_variables], prefix=categorical_variables)\n","# need to add inplace in oreder to drop columns.\n","loans_data.drop(columns=categorical_variables, axis=1, inplace=True)\n","loans_data = pandas.concat([loans_data, one_hot_data], axis=1)\n","\n","print(loans_data['grade_A'].values.sum())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["grade             object\n","term              object\n","home_ownership    object\n","emp_length        object\n","safe_loans         int64\n","dtype: object\n","['grade', 'term', 'home_ownership', 'emp_length']\n","6508\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_G75wJ4ssjzp"},"source":["## Train-test split\n","\n","We split the data into a train test split with 80% of the data in the training set and 20% of the data in the test set. We use `seed=1` so that everyone gets the same result."]},{"cell_type":"code","metadata":{"id":"amVqIsX3sjzp"},"source":["np.random.seed(1)\n","\n","train_data, test_data = train_test_split(loans_data, test_size=0.2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pdyY_w7Csjzq"},"source":["# Decision tree implementation\n","In this section, we will implement binary decision trees from scratch. There are several steps involved in building a decision tree. For that reason, we have split the entire assignment into several sections.\n","\n","## Function to count number of mistakes while predicting majority class\n","\n","Recall from the lecture that prediction at an intermediate node works by predicting the **majority class** for all data points that belong to this node.\n","\n","Now, we will write a function that calculates the number of **missclassified examples** when predicting the **majority class**. This will be used to help determine which feature is the best to split on at a given node of the tree.\n","\n","**Note**: Keep in mind that in order to compute the number of mistakes for a majority classifier, we only need the label (y values) of the data points in the node. \n","\n","** Steps to follow **:\n","* ** Step 1:** Calculate the number of safe loans and risky loans.\n","* ** Step 2:** Since we are assuming majority class prediction, all the data points that are **not** in the majority class are considered **mistakes**.\n","* ** Step 3:** Return the number of **mistakes**.\n","\n","\n","Now, let us write the function `intermediate_node_num_mistakes` which computes the number of misclassified examples of an intermediate node given the set of labels (y values) of the data points contained in the node. Fill in the places where you find `## YOUR CODE HERE`. There are **three** places in this function for you to fill in."]},{"cell_type":"code","metadata":{"id":"Uhfdu5gCsjzr"},"source":["def intermediate_node_num_mistakes(labels_in_node):\n","    # Corner case: If labels_in_node is empty, return 0\n","    if(len(labels_in_node) == 0):\n","        return 0\n","    \n","    # Count the number of 1's (safe loans)\n","    safe_loans = sum([1 if i == 1 else 0 for i in labels_in_node])\n","\n","    \n","    # Count the number of -1's (risky loans)\n","    risky_loans = sum([1 if i == -1 else 0 for i in labels_in_node]) \n","\n","                \n","    # Return the number of mistakes that the majority classifier makes.\n","    label = 1 if sum(labels_in_node) > 0 else -1\n","    \n","    if label == 1:\n","        return risky_loans\n","    else:\n","        return safe_loans"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E4jDt5K2sjzs"},"source":["Because there are several steps in this assignment, we have introduced some stopping points where you can check your code and make sure it is correct before proceeding. To test your `intermediate_node_num_mistakes` function, run the following code until you get a **Test passed!**, then you should proceed. Otherwise, you should spend some time figuring out where things went wrong."]},{"cell_type":"code","metadata":{"id":"oJXKPc6-sjzt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620204642597,"user_tz":-420,"elapsed":840,"user":{"displayName":"Khanh Vuong Tuan","photoUrl":"","userId":"10783698511148593600"}},"outputId":"8d3b005d-8c68-444c-8eef-733b2e10ff31"},"source":["# Test case 1\n","example_labels = np.array([-1, -1, 1, 1, 1])\n","if intermediate_node_num_mistakes(example_labels) == 2:\n","    print ('Test passed!')\n","else:\n","    print ('Test 1 failed... try again!')\n","\n","# Test case 2\n","example_labels = np.array([-1, -1, 1, 1, 1, 1, 1])\n","if intermediate_node_num_mistakes(example_labels) == 2:\n","    print ('Test passed!')\n","else:\n","    print ('Test 2 failed... try again!')\n","    \n","# Test case 3\n","example_labels = np.array([-1, -1, -1, -1, -1, 1, 1])\n","if intermediate_node_num_mistakes(example_labels) == 2:\n","    print ('Test passed!')\n","else:\n","    print ('Test 3 failed... try again!')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test passed!\n","Test passed!\n","Test passed!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5ODYfYn7sjzu"},"source":["## Function to pick best feature to split on\n","The function **best_splitting_feature** takes 3 arguments: \n","1. The data (DataFrame of data which includes all of the feature columns and label column)\n","2. The features to consider for splits (a list of strings of column names to consider for splits)\n","3. The name of the target/label column (string)\n","\n","The function will loop through the list of possible features, and consider splitting on each of them. It will calculate the classification error of each split and return the feature that had the smallest classification error when split on.\n","\n","Recall that the **classification error** is defined as follows:\n","$$\n","\\mbox{classification error} = \\frac{\\mbox{# mistakes}}{\\mbox{# total examples}}\n","$$\n","\n","Follow these steps: \n","* **Step 1:** Loop over each feature in the feature list\n","* **Step 2:** Within the loop, split the data into two groups: one group where all of the data has feature value 0 or False (we will call this the **left** split), and one group where all of the data has feature value 1 or True (we will call this the **right** split). Make sure the **left** split corresponds with 0 and the **right** split corresponds with 1 to ensure your implementation fits with our implementation of the tree building process.\n","* **Step 3:** Calculate the number of misclassified examples in both groups of data and use the above formula to compute the **classification error**.\n","* **Step 4:** If the computed error is smaller than the best error found so far, store this **feature and its error**.\n","\n","This may seem like a lot, but we have provided pseudocode in the comments in order to help you implement the function correctly.\n","\n","**Note:** Remember that since we are only dealing with binary features, we do not have to consider thresholds for real-valued features. This makes the implementation of this function much easier.\n","\n","Fill in the places where you find `## YOUR CODE HERE`. There are **five** places in this function for you to fill in."]},{"cell_type":"code","metadata":{"id":"ZrE2b6Zksjzv"},"source":["def best_splitting_feature(data, features, target):\n","    \n","    best_feature = None # Keep track of the best feature \n","    best_error = 10     # Keep track of the best error so far \n","    # Note: Since error is always <= 1, we should intialize it with something larger than 1.\n","\n","    # Convert to float to make sure error gets computed correctly.\n","    num_data_points = float(len(data))  \n","    \n","    # Loop through each feature to consider splitting on that feature\n","    for feature in features:\n","        \n","        # The left split will have all data points where the feature value is 0\n","        left_split = data[data[feature] == 0]\n","        \n","        # The right split will have all data points where the feature value is 1\n","        right_split =  data[data[feature] == 1]\n","\n","            \n","        # Calculate the number of misclassified examples in the left split.\n","        # Remember that we implemented a function for this! (It was called intermediate_node_num_mistakes)\n","        left_mistakes =  intermediate_node_num_mistakes(left_split['safe_loans'])   \n","  \n","\n","        # Calculate the number of misclassified examples in the right split.\n","        right_mistakes = intermediate_node_num_mistakes(right_split['safe_loans'])\n","\n","            \n","        # Compute the classification error of this split.\n","        # Error = (# of mistakes (left) + # of mistakes (right)) / (# of data points)\n","        ## YOUR CODE HERE\n","        error = (left_mistakes + right_mistakes) / data.shape[0]\n","\n","        # If this is the best error we have found so far, store the feature as best_feature and the error as best_error\n","        ## YOUR CODE HERE\n","        if error < best_error:\n","          best_error = error\n","          best_feature = feature\n","    \n","    return best_feature # Return the best feature we found"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7p_T1E-2sjzw"},"source":["To test your `best_splitting_feature` function, run the following code:"]},{"cell_type":"code","metadata":{"id":"rLQn6T5ssjzw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620204735038,"user_tz":-420,"elapsed":1832,"user":{"displayName":"Khanh Vuong Tuan","photoUrl":"","userId":"10783698511148593600"}},"outputId":"ce959b09-7c9c-4b23-d8e1-b76bc9989304"},"source":["features = list(loans_data.columns)\n","features.remove('safe_loans')\n","\n","if best_splitting_feature(train_data, features, 'safe_loans') == 'term_ 36 months':\n","    print('Test passed!')\n","else:\n","    print('Test failed... try again!')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Test passed!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vVrqeNH2sjzx"},"source":["## Building the tree\n","\n","With the above functions implemented correctly, we are now ready to build our decision tree. Each node in the decision tree is represented as a dictionary which contains the following keys and possible values:\n","\n","    { \n","       'is_leaf'            : True/False.\n","       'prediction'         : Prediction at the leaf node.\n","       'left'               : (dictionary corresponding to the left tree).\n","       'right'              : (dictionary corresponding to the right tree).\n","       'splitting_feature'  : The feature that this node splits on.\n","    }\n","\n","First, we will write a function that creates a leaf node given a set of target values. Fill in the places where you find `## YOUR CODE HERE`. There are **three** places in this function for you to fill in."]},{"cell_type":"code","metadata":{"id":"1k79CNNSsjzx"},"source":["def create_leaf(target_values):\n","    \n","    # Create a leaf node\n","    leaf = {'splitting_feature' : None,\n","            'left' : None,\n","            'right' : None,\n","            'is_leaf': True\n","            }\n","    \n","    # Count the number of data points that are +1 and -1 in this node.\n","    num_ones = target_values[target_values == +1].shape[0]\n","    num_minus_ones = target_values[target_values == -1].shape[0]\n","    \n","    # For the leaf node, set the prediction to be the majority class.\n","    # Store the predicted class (1 or -1) in leaf['prediction']\n","    if(num_ones > num_minus_ones):\n","      leaf['prediction'] = 1\n","    else:\n","      leaf['prediction'] = -1\n","        \n","    # Return the leaf node        \n","    return leaf "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v-DvHK1Esjzy"},"source":["We have provided a function that learns the decision tree recursively and implements 3 stopping conditions:\n","1. **Stopping condition 1:** All data points in a node are from the same class.\n","2. **Stopping condition 2:** No more features to split on.\n","3. **Additional stopping condition:** In addition to the above two stopping conditions covered in lecture, in this assignment we will also consider a stopping condition based on the **max_depth** of the tree. By not letting the tree grow too deep, we will save computational effort in the learning process. \n","\n","Now, we will write down the skeleton of the learning algorithm. Fill in the places where you find `## YOUR CODE HERE`. There are **seven** places in this function for you to fill in."]},{"cell_type":"code","metadata":{"id":"2rY2ePefsjzy"},"source":["def decision_tree_create(data, features, target, current_depth = 0, max_depth = 10):\n","    remaining_features = features[:] # Make a copy of the features.\n","    \n","    target_values = data[target]\n","    print (\"--------------------------------------------------------------------\")\n","    print (\"Subtree, depth = %s (%s data points).\" % (current_depth, target_values.shape[0]))\n","    \n","\n","    # Stopping condition 1\n","    # (Check if there are mistakes at current node.\n","    # Recall you wrote a function intermediate_node_num_mistakes to compute this.)\n","    if (intermediate_node_num_mistakes(target_values) == 0):  ## YOUR CODE HERE\n","        print (\"Stopping condition 1 reached.\")     \n","        # If not mistakes at current node, make current node a leaf node\n","        return create_leaf(target_values)\n","    \n","    # Stopping condition 2 (check if there are remaining features to consider splitting on)\n","    if (remaining_features == []):   ## YOUR CODE HERE\n","        print (\"Stopping condition 2 reached.\")    \n","        # If there are no remaining features to consider, make current node a leaf node\n","        return create_leaf(target_values)    \n","    \n","    # Additional stopping condition (limit tree depth)\n","    if (current_depth >= max_depth):  ## YOUR CODE HERE\n","        print (\"Reached maximum depth. Stopping for now.\")\n","        # If the max tree depth has been reached, make current node a leaf node\n","        return create_leaf(target_values)\n","\n","    # Find the best splitting feature (recall the function best_splitting_feature implemented above)\n","    ## YOUR CODE HERE\n","    splitting_feature = best_splitting_feature(data, remaining_features, target)\n","    \n","    # Split on the best feature that we found. \n","    left_split = data[data[splitting_feature] == 0]\n","    right_split = data[data[splitting_feature] == 1]\n","    remaining_features.remove(splitting_feature)\n","    print (\"Split on feature %s. (%s, %s)\" % (\\\n","                      splitting_feature, len(left_split), len(right_split)))\n","    \n","    # Create a leaf node if the split is \"perfect\"\n","    if left_split.shape[0] == data.shape[0]:\n","        print (\"Creating leaf node.\")\n","        return create_leaf(left_split[target])\n","    if right_split.shape[0] == data.shape[0]:\n","        print (\"Creating leaf node.\")\n","        ## YOUR CODE HERE\n","        return create_leaf(right_split[target])\n","        \n","    # Repeat (recurse) on left and right subtrees\n","    left_tree = decision_tree_create(left_split, remaining_features, target, current_depth + 1, max_depth)        \n","    ## YOUR CODE HERE\n","    right_tree = decision_tree_create(right_split, remaining_features, target, current_depth + 1, max_depth)\n","\n","    return {'is_leaf'          : False, \n","            'prediction'       : None,\n","            'splitting_feature': splitting_feature,\n","            'left'             : left_tree, \n","            'right'            : right_tree}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4_wWhNBcsjzz"},"source":["Here is a recursive function to count the nodes in your tree:"]},{"cell_type":"code","metadata":{"id":"kt7cvH0Xsjz0"},"source":["def count_nodes(tree):\n","    if tree['is_leaf']:\n","        return 1\n","    return 1 + count_nodes(tree['left']) + count_nodes(tree['right'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_NM_Tmtvsjz0"},"source":["Run the following test code to check your implementation. Make sure you get **'Test passed'** before proceeding."]},{"cell_type":"code","metadata":{"id":"KbO7Y8Vjsjz0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620204890008,"user_tz":-420,"elapsed":2699,"user":{"displayName":"Khanh Vuong Tuan","photoUrl":"","userId":"10783698511148593600"}},"outputId":"482d3a42-8d8c-4dc8-a2bb-7e1ff40c2266"},"source":["small_data_decision_tree = decision_tree_create(train_data, features, 'safe_loans', max_depth = 3)\n","if count_nodes(small_data_decision_tree) == 13:\n","    print ('Test passed!')\n","else:\n","    print ('Test failed... try again!')\n","    print ('Number of nodes found                :', count_nodes(small_data_decision_tree))\n","    print ('Number of nodes that should be there : 13')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--------------------------------------------------------------------\n","Subtree, depth = 0 (37040 data points).\n","Split on feature term_ 36 months. (9419, 27621)\n","--------------------------------------------------------------------\n","Subtree, depth = 1 (9419 data points).\n","Split on feature grade_A. (9293, 126)\n","--------------------------------------------------------------------\n","Subtree, depth = 2 (9293 data points).\n","Split on feature grade_B. (8227, 1066)\n","--------------------------------------------------------------------\n","Subtree, depth = 3 (8227 data points).\n","Reached maximum depth. Stopping for now.\n","--------------------------------------------------------------------\n","Subtree, depth = 3 (1066 data points).\n","Reached maximum depth. Stopping for now.\n","--------------------------------------------------------------------\n","Subtree, depth = 2 (126 data points).\n","Split on feature home_ownership_MORTGAGE. (36, 90)\n","--------------------------------------------------------------------\n","Subtree, depth = 3 (36 data points).\n","Reached maximum depth. Stopping for now.\n","--------------------------------------------------------------------\n","Subtree, depth = 3 (90 data points).\n","Reached maximum depth. Stopping for now.\n","--------------------------------------------------------------------\n","Subtree, depth = 1 (27621 data points).\n","Split on feature grade_D. (22974, 4647)\n","--------------------------------------------------------------------\n","Subtree, depth = 2 (22974 data points).\n","Split on feature grade_E. (21728, 1246)\n","--------------------------------------------------------------------\n","Subtree, depth = 3 (21728 data points).\n","Reached maximum depth. Stopping for now.\n","--------------------------------------------------------------------\n","Subtree, depth = 3 (1246 data points).\n","Reached maximum depth. Stopping for now.\n","--------------------------------------------------------------------\n","Subtree, depth = 2 (4647 data points).\n","Split on feature grade_A. (4647, 0)\n","Creating leaf node.\n","Test passed!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SOVjqFDtsjz1"},"source":["## Build the tree!\n","\n","Now that all the tests are passing, we will train a tree model on the **train_data**. Limit the depth to 6 (**max_depth = 6**) to make sure the algorithm doesn't run for too long. Call this tree **my_decision_tree**. \n","\n","**Warning**: This code block may take 1-2 minutes to learn. "]},{"cell_type":"code","metadata":{"id":"HHvZPdRvsjz1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620204911641,"user_tz":-420,"elapsed":6148,"user":{"displayName":"Khanh Vuong Tuan","photoUrl":"","userId":"10783698511148593600"}},"outputId":"c1baa303-2ca0-4f64-b466-73ed4308edee"},"source":["# YOUR CODE HERE\n","my_decision_tree = decision_tree_create(train_data, features, target, 0, 6)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--------------------------------------------------------------------\n","Subtree, depth = 0 (37040 data points).\n","Split on feature term_ 36 months. (9419, 27621)\n","--------------------------------------------------------------------\n","Subtree, depth = 1 (9419 data points).\n","Split on feature grade_A. (9293, 126)\n","--------------------------------------------------------------------\n","Subtree, depth = 2 (9293 data points).\n","Split on feature grade_B. (8227, 1066)\n","--------------------------------------------------------------------\n","Subtree, depth = 3 (8227 data points).\n","Split on feature grade_C. (5974, 2253)\n","--------------------------------------------------------------------\n","Subtree, depth = 4 (5974 data points).\n","Split on feature grade_D. (3891, 2083)\n","--------------------------------------------------------------------\n","Subtree, depth = 5 (3891 data points).\n","Split on feature grade_E. (1721, 2170)\n","--------------------------------------------------------------------\n","Subtree, depth = 6 (1721 data points).\n","Reached maximum depth. Stopping for now.\n","--------------------------------------------------------------------\n","Subtree, depth = 6 (2170 data points).\n","Reached maximum depth. Stopping for now.\n","--------------------------------------------------------------------\n","Subtree, depth = 5 (2083 data points).\n","Split on feature grade_E. (2083, 0)\n","Creating leaf node.\n","--------------------------------------------------------------------\n","Subtree, depth = 4 (2253 data points).\n","Split on feature grade_D. (2253, 0)\n","Creating leaf node.\n","--------------------------------------------------------------------\n","Subtree, depth = 3 (1066 data points).\n","Split on feature emp_length_5 years. (986, 80)\n","--------------------------------------------------------------------\n","Subtree, depth = 4 (986 data points).\n","Split on feature emp_length_3 years. (900, 86)\n","--------------------------------------------------------------------\n","Subtree, depth = 5 (900 data points).\n","Split on feature grade_C. (900, 0)\n","Creating leaf node.\n","--------------------------------------------------------------------\n","Subtree, depth = 5 (86 data points).\n","Split on feature home_ownership_MORTGAGE. (39, 47)\n","--------------------------------------------------------------------\n","Subtree, depth = 6 (39 data points).\n","Reached maximum depth. Stopping for now.\n","--------------------------------------------------------------------\n","Subtree, depth = 6 (47 data points).\n","Reached maximum depth. Stopping for now.\n","--------------------------------------------------------------------\n","Subtree, depth = 4 (80 data points).\n","Split on feature home_ownership_RENT. (58, 22)\n","--------------------------------------------------------------------\n","Subtree, depth = 5 (58 data points).\n","Split on feature grade_C. (58, 0)\n","Creating leaf node.\n","--------------------------------------------------------------------\n","Subtree, depth = 5 (22 data points).\n","Split on feature grade_C. (22, 0)\n","Creating leaf node.\n","--------------------------------------------------------------------\n","Subtree, depth = 2 (126 data points).\n","Split on feature home_ownership_MORTGAGE. (36, 90)\n","--------------------------------------------------------------------\n","Subtree, depth = 3 (36 data points).\n","Split on feature emp_length_< 1 year. (26, 10)\n","--------------------------------------------------------------------\n","Subtree, depth = 4 (26 data points).\n","Split on feature emp_length_2 years. (23, 3)\n","--------------------------------------------------------------------\n","Subtree, depth = 5 (23 data points).\n","Split on feature emp_length_5 years. (20, 3)\n","--------------------------------------------------------------------\n","Subtree, depth = 6 (20 data points).\n","Reached maximum depth. Stopping for now.\n","--------------------------------------------------------------------\n","Subtree, depth = 6 (3 data points).\n","Reached maximum depth. Stopping for now.\n","--------------------------------------------------------------------\n","Subtree, depth = 5 (3 data points).\n","Split on feature grade_B. (3, 0)\n","Creating leaf node.\n","--------------------------------------------------------------------\n","Subtree, depth = 4 (10 data points).\n","Split on feature grade_B. (10, 0)\n","Creating leaf node.\n","--------------------------------------------------------------------\n","Subtree, depth = 3 (90 data points).\n","Split on feature grade_B. (90, 0)\n","Creating leaf node.\n","--------------------------------------------------------------------\n","Subtree, depth = 1 (27621 data points).\n","Split on feature grade_D. (22974, 4647)\n","--------------------------------------------------------------------\n","Subtree, depth = 2 (22974 data points).\n","Split on feature grade_E. (21728, 1246)\n","--------------------------------------------------------------------\n","Subtree, depth = 3 (21728 data points).\n","Split on feature grade_C. (14570, 7158)\n","--------------------------------------------------------------------\n","Subtree, depth = 4 (14570 data points).\n","Split on feature grade_F. (14207, 363)\n","--------------------------------------------------------------------\n","Subtree, depth = 5 (14207 data points).\n","Split on feature grade_G. (14097, 110)\n","--------------------------------------------------------------------\n","Subtree, depth = 6 (14097 data points).\n","Reached maximum depth. Stopping for now.\n","--------------------------------------------------------------------\n","Subtree, depth = 6 (110 data points).\n","Reached maximum depth. Stopping for now.\n","--------------------------------------------------------------------\n","Subtree, depth = 5 (363 data points).\n","Split on feature grade_A. (363, 0)\n","Creating leaf node.\n","--------------------------------------------------------------------\n","Subtree, depth = 4 (7158 data points).\n","Split on feature home_ownership_RENT. (3458, 3700)\n","--------------------------------------------------------------------\n","Subtree, depth = 5 (3458 data points).\n","Split on feature emp_length_< 1 year. (3257, 201)\n","--------------------------------------------------------------------\n","Subtree, depth = 6 (3257 data points).\n","Reached maximum depth. Stopping for now.\n","--------------------------------------------------------------------\n","Subtree, depth = 6 (201 data points).\n","Reached maximum depth. Stopping for now.\n","--------------------------------------------------------------------\n","Subtree, depth = 5 (3700 data points).\n","Split on feature emp_length_2 years. (3279, 421)\n","--------------------------------------------------------------------\n","Subtree, depth = 6 (3279 data points).\n","Reached maximum depth. Stopping for now.\n","--------------------------------------------------------------------\n","Subtree, depth = 6 (421 data points).\n","Reached maximum depth. Stopping for now.\n","--------------------------------------------------------------------\n","Subtree, depth = 3 (1246 data points).\n","Split on feature grade_A. (1246, 0)\n","Creating leaf node.\n","--------------------------------------------------------------------\n","Subtree, depth = 2 (4647 data points).\n","Split on feature grade_A. (4647, 0)\n","Creating leaf node.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"YDlvBrK8sjz2"},"source":["## Making predictions with a decision tree\n","\n","As discussed in the lecture, we can make predictions from the decision tree with a simple recursive function. Below, we call this function `classify`, which takes in a learned `tree` and a test point `x` to classify.  We include an option `annotate` that describes the prediction path when set to `True`.\n","\n","Fill in the places where you find `## YOUR CODE HERE`. There is **one** place in this function for you to fill in."]},{"cell_type":"code","metadata":{"id":"B70Bq1Cusjz2"},"source":["def classify(tree, x, annotate = False):   \n","    # if the node is a leaf node.\n","    if tree['is_leaf']:\n","        if annotate: \n","            print (\"At leaf, predicting %s\" % tree['prediction'])\n","        return tree['prediction'] \n","    else:\n","        # split on feature.\n","        split_feature_value = x[tree['splitting_feature']]\n","        if annotate: \n","            print (\"Split on %s = %s\" % (tree['splitting_feature'], split_feature_value))\n","        if split_feature_value == 0:\n","            return classify(tree['left'], x, annotate)\n","        else:\n","            return classify(tree['right'], x, annotate)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-TE9SoDXsjz2"},"source":["Now, let's consider the first example of the test set and see what `my_decision_tree` model predicts for this data point."]},{"cell_type":"code","metadata":{"id":"XRV8PnWAsjz3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620204927455,"user_tz":-420,"elapsed":784,"user":{"displayName":"Khanh Vuong Tuan","photoUrl":"","userId":"10783698511148593600"}},"outputId":"5fefad61-2800-4665-a00d-2452d5f01dca"},"source":["test_data.iloc[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["safe_loans                -1\n","grade_A                    0\n","grade_B                    0\n","grade_C                    0\n","grade_D                    0\n","grade_E                    1\n","grade_F                    0\n","grade_G                    0\n","term_ 36 months            1\n","term_ 60 months            0\n","home_ownership_MORTGAGE    0\n","home_ownership_OTHER       0\n","home_ownership_OWN         0\n","home_ownership_RENT        1\n","emp_length_1 year          0\n","emp_length_10+ years       1\n","emp_length_2 years         0\n","emp_length_3 years         0\n","emp_length_4 years         0\n","emp_length_5 years         0\n","emp_length_6 years         0\n","emp_length_7 years         0\n","emp_length_8 years         0\n","emp_length_9 years         0\n","emp_length_< 1 year        0\n","Name: 121355, dtype: int64"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"RnHSgMefsjz3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620204931321,"user_tz":-420,"elapsed":773,"user":{"displayName":"Khanh Vuong Tuan","photoUrl":"","userId":"10783698511148593600"}},"outputId":"a7d822c9-db95-4b3b-d188-6457c253ea1d"},"source":["print ('Predicted class: %s ' % classify(my_decision_tree, test_data.iloc[0]))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Predicted class: -1 \n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"OJwALTDQsjz3"},"source":["Let's add some annotations to our prediction to see what the prediction path was that lead to this predicted class:"]},{"cell_type":"code","metadata":{"id":"L3BTUE3osjz4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620204933987,"user_tz":-420,"elapsed":602,"user":{"displayName":"Khanh Vuong Tuan","photoUrl":"","userId":"10783698511148593600"}},"outputId":"34836f49-5bf1-454e-c849-8466bcf853dc"},"source":["classify(my_decision_tree, test_data.iloc[0], annotate=True)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Split on term_ 36 months = 1\n","Split on grade_D = 0\n","Split on grade_E = 1\n","At leaf, predicting -1\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["-1"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"markdown","metadata":{"id":"1uIw_jx4sjz4"},"source":["**Quiz Question:** What was the feature that **my_decision_tree** first split on while making the prediction for test_data[0]?\n","<br>\n","**Your answer:** \n","<br>\n","**Quiz Question:** What was the first feature that lead to a right split of test_data[0]?\n","<br>\n","**Your answer:**\n","<br>\n","**Quiz Question:** What was the last feature split on before reaching a leaf node for test_data[0]?\n","<br>\n","**Your answer:** "]},{"cell_type":"markdown","metadata":{"id":"ciP4b6gvsjz5"},"source":["## Evaluating your decision tree\n","Now, we will write a function to evaluate a decision tree by computing the classification error of the tree on the given dataset.\n","\n","Again, recall that the **classification error** is defined as follows:\n","$$\n","\\mbox{classification error} = \\frac{\\mbox{# mistakes}}{\\mbox{# total examples}}\n","$$\n","\n","Now, write a function called `evaluate_classification_error` that takes in as input:\n","1. `tree` (as described above)\n","2. `data` (an DataFrame)\n","3. `target` (a string - the name of the target/label column)\n","\n","This function should calculate a prediction (class label) for each row in `data` using the decision `tree` and return the classification error computed using the above formula. Fill in the places where you find `## YOUR CODE HERE`. There is **one** place in this function for you to fill in."]},{"cell_type":"code","metadata":{"id":"xmuWYvmwsjz5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620205090038,"user_tz":-420,"elapsed":756,"user":{"displayName":"Khanh Vuong Tuan","photoUrl":"","userId":"10783698511148593600"}},"outputId":"48a9c3d7-73db-4bec-9135-00e0b0166d1b"},"source":["print(test_data.shape[0])\n","def evaluate_classification_error(tree, data, target):\n","    # Apply the classify(tree, x) to each row in your data\n","    prediction = []\n","    for i, row in data.iterrows():\n","        prediction.append(classify(tree, row))\n","    \n","    # Once you've made the predictions, calculate the classification error and return it\n","    ## YOUR CODE HERE\n","    right = data[data['safe_loans'] == prediction]\n","    return 1 - len(right)*1.0/len(data)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["9260\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BiZauc_Vsjz5"},"source":["Now, let's use this function to evaluate the classification error on the test set."]},{"cell_type":"code","metadata":{"id":"8m_g-_8zsjz6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620205093370,"user_tz":-420,"elapsed":1627,"user":{"displayName":"Khanh Vuong Tuan","photoUrl":"","userId":"10783698511148593600"}},"outputId":"31e02179-9513-42bc-e314-fb2fe6962fd3"},"source":["evaluate_classification_error(my_decision_tree, test_data, 'safe_loans')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.3827213822894169"]},"metadata":{"tags":[]},"execution_count":33}]},{"cell_type":"markdown","metadata":{"id":"lBlWG5Amsjz6"},"source":["**Quiz Question:** Rounded to 2nd decimal point, what is the classification error of **my_decision_tree** on the **test_data**?\n","<br>\n","**Your answer:** 0.38"]}]}